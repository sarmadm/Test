{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BjEy5BHKIdHs",
    "outputId": "00042f4d-bee3-4142-b57f-753b80d2ec72"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!pip install tensorflow-gpu keras\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "# import plotly.offline as ofply\n",
    "# import plotly.graph_objs as go\n",
    "# from plotly import tools as plytools\n",
    "\n",
    "# %matplotlib inline\n",
    "# # import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "import importlib\n",
    "from IPython.display import Markdown\n",
    "import IPython\n",
    "# ofply.init_notebook_mode()\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "pd.core.config.options.display.max_columns = 100\n",
    "import keras\n",
    "from keras.layers import Input, Dense, LSTM, Bidirectional, Flatten, LocallyConnected1D, BatchNormalization, Conv1D, Conv2D, Conv3D, Reshape, Activation, Add, RepeatVector, MaxoutDense\n",
    "from keras.layers import MaxPool1D, AvgPool1D, concatenate, ActivityRegularization, GlobalAvgPool1D, Dropout, Lambda, UpSampling1D, TimeDistributed, GlobalAvgPool2D, AlphaDropout\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "#from keras.constraints import maxnorm\n",
    "#from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.backend import clear_session\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import activations\n",
    "from keras import backend as K\n",
    "from keras.layers.merge import add\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_validate, ParameterGrid, KFold, StratifiedKFold\n",
    "from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas\n",
    "import pandas as pd\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D,ZeroPadding2D,AveragePooling2D,Conv1D,MaxPooling1D\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KWqfhXHxRQum"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aur_dev (230, 1560, 17)\n",
      "auc_dev (230, 1560, 18)\n",
      "eye_dev (230, 1560, 8)\n",
      "Ymrs_dev (230,)\n",
      "Y_train (230,)\n",
      "Y_oh.shape (230, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarmad\\Anaconda3\\envs\\keras_v\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# load dev dataset dictionary\n",
    "dev_dataset= pd.read_pickle('Z:/eee_comms1/Shared/Avec2018Project/pkls/auc_pkls/dev_tw_dataset_mat_dict.pkl')\n",
    "aur_dev_tw = dev_dataset['au_r_dataset_mat']\n",
    "auc_dev_tw= dev_dataset['au_c_dataset_mat']\n",
    "eye_dev_tw = dev_dataset['eye_dataset_mat']\n",
    "pose_dev_tw = dev_dataset['pose_dataset_mat']\n",
    "Y_int= dev_dataset['Y']\n",
    "\n",
    "\n",
    "Ymrs_dev= dev_dataset['Ymrs'] / max(dev_dataset['Ymrs'])   # maybe standardization is better\n",
    "del dev_dataset\n",
    "\n",
    "# confirm shapes\n",
    "print('aur_dev',aur_dev_tw.shape)\n",
    "print('auc_dev',auc_dev_tw.shape)\n",
    "print('eye_dev',eye_dev_tw.shape)\n",
    "print('Ymrs_dev',Ymrs_dev.shape)\n",
    "print('Y_train',Y_int.shape)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_encoder = OneHotEncoder()\n",
    "y_sparse = y_encoder.fit_transform(Y_int.reshape((len(Y_int),1)))\n",
    "Y_oh_dev = y_sparse.toarray()\n",
    "print('Y_oh.shape',Y_oh_dev.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "glLsf4C-yl_z"
   },
   "outputs": [],
   "source": [
    "# load train dataset dictionary\n",
    "train_dataset= pd.read_pickle('Z:/eee_comms1/Shared/Avec2018Project/pkls/auc_pkls/train_tw_dataset_mat_dict.pkl')\n",
    "aur_train_tw = train_dataset['au_r_dataset_mat']\n",
    "auc_train_tw = train_dataset['au_c_dataset_mat']\n",
    "eye_train_tw= train_dataset['eye_dataset_mat']\n",
    "pose_train_tw = train_dataset['pose_dataset_mat']\n",
    "Y_int= train_dataset['Y']\n",
    "\n",
    "\n",
    "Ymrs_train= train_dataset['Ymrs'] / max(train_dataset['Ymrs'])   # maybe standardization is better\n",
    "del train_dataset\n",
    "\n",
    "# confirm shapes\n",
    "print('aur_train',aur_train_tw.shape)\n",
    "print('auc_train',auc_train_tw.shape)\n",
    "print('eye_train',eye_train_tw.shape)\n",
    "print('Ymrs_train',Ymrs_train.shape)\n",
    "print('Y_train',Y_int.shape)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_encoder = OneHotEncoder()\n",
    "y_sparse = y_encoder.fit_transform(Y_int.reshape((len(Y_int),1)))\n",
    "Y_oh_tr = y_sparse.toarray()\n",
    "print('Y_oh.shape',Y_oh_tr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "0ooGPAepAmBV",
    "outputId": "cf9d4f4b-03c3-42d7-c267-7338ca46bb37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eye_train (104, 56)\n",
      "eye_dev (60, 56)\n",
      "**************\n",
      "              \n",
      "pose_train (104, 20)\n",
      "pose_dev (60, 20)\n",
      "**************\n",
      "              \n",
      "auc_train (104, 78)\n",
      "auc_dev (60, 78)\n",
      "**************\n",
      "              \n",
      "sumerized_train_feats (104, 154)\n",
      "sumerized_dev_feats (60, 154)\n"
     ]
    }
   ],
   "source": [
    "# Selected summerised features\n",
    "\n",
    "\n",
    "\n",
    "# load dev dataset dictionary \n",
    "eye_dataset= pd.read_pickle('Z:/eee_comms1/Shared/Avec2018Project/pkls/auc_pkls/eye_classification.pkl')\n",
    "eye_train=eye_dataset['sel_train_bagging_train']\n",
    "eye_dev=eye_dataset['sel_test_bagging_dev']\n",
    "\n",
    "\n",
    "print('eye_train',eye_train.shape)\n",
    "print('eye_dev',eye_dev.shape)\n",
    "\n",
    "print('**************')\n",
    "print('              ')\n",
    "\n",
    "pose_dataset= pd.read_pickle('Z:/eee_comms1/Shared/Avec2018Project/pkls/auc_pkls/pose_classification.pkl')\n",
    "pose_train=pose_dataset['sel_train_bagging_train']\n",
    "pose_dev=pose_dataset['sel_test_bagging_dev']\n",
    "\n",
    "print('pose_train',pose_train.shape)\n",
    "print('pose_dev',pose_dev.shape)\n",
    "\n",
    "\n",
    "print('**************')\n",
    "print('              ')\n",
    "\n",
    "\n",
    "auc_dataset= pd.read_pickle('Z:/eee_comms1/Shared/Avec2018Project/pkls/auc_pkls/auc_classification.pkl')\n",
    "auc_train=auc_dataset['sel_train_bagging_train']\n",
    "auc_dev=auc_dataset['sel_test_bagging_dev']\n",
    "\n",
    "\n",
    "print('auc_train',auc_train.shape)\n",
    "print('auc_dev',auc_dev.shape)\n",
    "\n",
    "\n",
    "\n",
    "print('**************')\n",
    "print('              ')\n",
    "\n",
    "\n",
    "sumerized_train_feats=pd.concat([auc_train,eye_train,pose_train], axis=1, sort=False)\n",
    "sumerized_dev_feats=pd.concat([auc_dev,eye_dev,pose_dev], axis=1, sort=False)\n",
    "\n",
    "\n",
    "\n",
    "print('sumerized_train_feats',sumerized_train_feats.shape)\n",
    "print('sumerized_dev_feats',sumerized_dev_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pCjvzvtW_CPX"
   },
   "outputs": [],
   "source": [
    "def GlobalRichPool(inputs, name=None):\n",
    "\n",
    "    out_avg = Lambda(K.mean, arguments={'axis':1})(inputs)\n",
    "    out_std = Lambda(K.std, arguments={'axis':1})(inputs)\n",
    "    out_max = Lambda(K.max, arguments={'axis':1})(inputs)\n",
    "#     out_lse = Lambda(K.logsumexp, arguments={'axis':1})(inputs)\n",
    "    \n",
    "    if name:\n",
    "        out = concatenate([out_avg, out_std, out_max], name=name)\n",
    "    else:\n",
    "        out = concatenate([out_avg, out_std, out_max])\n",
    "    \n",
    "    return out\n",
    "  \n",
    "  \n",
    "def bnrelu(inpt):\n",
    "    inpt = BatchNormalization(axis=-1)(inpt)\n",
    "    inpt = layers.ReLU()(inpt)\n",
    "#     inpt = Activation('relu')(inpt)\n",
    "    return inpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "77cbHIC-_Cnn"
   },
   "outputs": [],
   "source": [
    "# Joint sequence extraction\n",
    "def conv_seq():\n",
    "\n",
    "    inshape_aur = aur_train_tw.shape[1:]\n",
    "    inshape_auc = auc_train_tw.shape[1:]\n",
    "    inshape_eye = eye_train_tw.shape[1:]\n",
    "    inshape_pose = pose_train_tw.shape[1:]\n",
    "    inshape_ofsum = sumerized_train_feats.shape[1:]\n",
    "    \n",
    "    outshape = len(np.unique(Y_int))\n",
    "\n",
    "    ## some defaults\n",
    "    # initializers, optimizers, constraints\n",
    "    adam = optimizers.adam()\n",
    "    init = initializers.he_normal()\n",
    "    fc_act = 'relu'\n",
    "    init_c = initializers.he_uniform()\n",
    "    binit = 'zeros'\n",
    "    #    binit_c = initializers.glorot_normal()\n",
    "    binit_c = 'zeros'\n",
    "\n",
    "    outlist = []\n",
    "    outlist2 = []\n",
    "\n",
    "    ### Model declaration\n",
    "    ## Inputs\n",
    "    # AU\n",
    "    aur_in = Input(shape=inshape_aur, name='AUR_input')\n",
    "    print('aur_in shape',aur_in)\n",
    "    aur = aur_in\n",
    "    raw_globalpool = GlobalRichPool(aur, name='raw_globalpool_aur')\n",
    "    outlist.append(raw_globalpool)\n",
    "\n",
    "    auc_in = Input(shape=inshape_auc, name='AUC_input')\n",
    "    auc = auc_in\n",
    "    raw_globalpool = GlobalRichPool(auc, name='raw_globalpool_auc')\n",
    "    outlist.append(raw_globalpool)\n",
    "\n",
    "    print('auc in ',auc.shape)\n",
    "    # EYE\n",
    "    eye_in = Input(shape=inshape_eye, name='EYE_input')\n",
    "    eye = eye_in\n",
    "    raw_globalpool = GlobalRichPool(eye, name='raw_globalpool_eye')\n",
    "    outlist.append(raw_globalpool)\n",
    "\n",
    "    # POSE\n",
    "    pose_in = Input(shape=inshape_pose, name='Pose_input')\n",
    "    pose = pose_in\n",
    "    raw_globalpool = GlobalRichPool(pose, name='raw_globalpool_pose')\n",
    "    outlist.append(raw_globalpool)\n",
    "    \n",
    "    # Openface classification summary\n",
    "    ofsum_in = Input(shape=inshape_ofsum, name='OFsum_input')\n",
    "    ofsum = ofsum_in\n",
    "    outlist.append(ofsum)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Concat over channels and\n",
    "    # sequence extraction\n",
    "    combined = concatenate([aur,auc, eye, pose], name='chan_concat')\n",
    "    print('combined',combined.shape)\n",
    "\n",
    "    \n",
    "\n",
    "   \n",
    "    kreg = regularizers.l1_l2(l1=0.1)\n",
    "    \n",
    "    combined = BatchNormalization()(combined)\n",
    "\n",
    "    seq = Conv1D(filters=64, kernel_size=5, strides=1, padding='same', name='seq1')(combined)\n",
    "    seq=bnrelu(seq)\n",
    "    seq = MaxPooling1D(pool_size=2, strides=2)(seq)\n",
    "    \n",
    "    \n",
    "    \n",
    "    seq = Conv1D(filters=96, kernel_size=5, strides=1,padding='same', name='seq2')(seq)\n",
    "    seq=bnrelu(seq)\n",
    "    seq =MaxPooling1D(pool_size=2, strides=2)(seq)\n",
    "    \n",
    "    \n",
    "    \n",
    "    seq = Conv1D(filters=96, kernel_size=5, strides=1, padding='same', name='seq3')(seq)\n",
    "    seq=bnrelu(seq)\n",
    "    globalpool = GlobalRichPool(seq, name='seq_globalpool_ms')\n",
    "    outlist.append(globalpool)\n",
    "    # receptive field = 20 timesteps\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    seq = MaxPooling1D(pool_size=2, strides=2)(seq)\n",
    "    seq = Conv1D(filters=96, kernel_size=5, strides=1,padding='same', name='seq4')(seq)\n",
    "    seq=bnrelu(seq)\n",
    "    seq = MaxPooling1D(pool_size=2, strides=2)(seq)\n",
    "    \n",
    "    \n",
    "    seq = Conv1D(filters=96, kernel_size=5, strides=1,padding='same', name='seq5')(seq)\n",
    "    seq=bnrelu(seq)\n",
    "    globalpool = GlobalRichPool(seq, name='seq_globalpool_s')\n",
    "    outlist.append(globalpool)\n",
    "    # receptive field = 80 timesteps\n",
    "    \n",
    "    \n",
    "    \n",
    "    seq = MaxPooling1D(pool_size=3, strides=3)(seq)\n",
    "    seq = Conv1D(filters=96, kernel_size=5, strides=1, padding='same',name='seq6')(seq)\n",
    "    seq=bnrelu(seq)\n",
    "    globalpool = GlobalRichPool(seq, name='seq_globalpool_8s')\n",
    "    \n",
    "    \n",
    "    \n",
    "    outlist.append(globalpool)\n",
    "    # receptive field = 240 timesteps, 8 seconds\n",
    "    \n",
    "    # Fully connected layers\n",
    "\n",
    "    out_combined = concatenate(outlist, name='feat_concat',axis=1)\n",
    "    out = out_combined\n",
    "    print('Feat combined shape', out.shape )\n",
    "\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Dropout(0.5)(out)\n",
    "    kreg = regularizers.l1_l2(l1=0, l2=0.01)\n",
    "    out = Dense(512, activation=fc_act, kernel_regularizer=kreg)(out)\n",
    "    out = Dense(512, activation=fc_act, kernel_regularizer=kreg)(out)\n",
    "#     out = Dense(512, activation=fc_act, kernel_regularizer=kreg)(out)\n",
    "\n",
    "\n",
    "    out_class = Dense(outshape, activation='softmax', name='out_class')(out)\n",
    "    out_reg = Dense(1, activation='linear', name='out_reg')(out)\n",
    "    # out_class = Lambda(gen_class_output, name='out_class')(out_reg)\n",
    "\n",
    "\n",
    "    model = Model(inputs=[aur_in,auc_in, eye_in, pose_in, ofsum_in], outputs=[out_class, out_reg])\n",
    "    metrics = {'out_class':['categorical_accuracy'], 'out_reg':'mean_absolute_error'}\n",
    "    loss    = {'out_class':'categorical_crossentropy', 'out_reg':'mean_absolute_error'}\n",
    "    loss_weights = {'out_class': 0.5, 'out_reg':0.5}\n",
    "    model.compile(optimizer=adam, loss=loss, metrics=metrics, loss_weights=loss_weights)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Po1HKNyNbgI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qTMH7K26a9V8"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def normalize_input(input):\n",
    "  \n",
    "  data= input\n",
    "  scalers = {}\n",
    "  for i in range(data.shape[2]):\n",
    "      scalers[i] = StandardScaler()\n",
    "      data[:, :, i] = scalers[i].fit_transform(data[:, :, i]) \n",
    "  return(data)\n",
    "      \n",
    "# import numpy as np\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# train_data=aur_train_tw\n",
    "# scaler = StandardScaler()\n",
    "# num_instances, num_time_steps, num_features = train_data.shape\n",
    "\n",
    "# train_data = np.reshape(train_data, (-1, num_features))\n",
    "# print('train_data.shape',train_data.shape)\n",
    "# train_data = scaler.fit_transform(train_data)\n",
    "\n",
    "\n",
    "# train_data = np.reshape(train_data, (num_instances, num_time_steps, num_features))\n",
    "# print('train_data',train_data)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def normalize_2d_input(input):\n",
    "  \n",
    "  mean = input.mean(axis=0)\n",
    "  input -= mean\n",
    "  std = input.std(axis=0)\n",
    "  input /= std\n",
    " \n",
    "  return(input)\n",
    "\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "xFaxYZRFEL-N",
    "outputId": "50f5809f-8a44-44f0-ce70-09da3c65620a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            train data          \n",
      "aur_train (530, 1560, 17)\n",
      "auc_train (530, 1560, 18)\n",
      "eye_train (530, 1560, 8)\n",
      "pose_train (530, 1560, 6)\n",
      "y_train (530, 3)\n",
      "y_train_ymrs (530,)\n",
      "sumerized_train_feats (104, 154)\n",
      "                         \n",
      "*************dev data************\n",
      "                         \n",
      "aur_dev (230, 1560, 17)\n",
      "auc_dev (230, 1560, 18)\n",
      "eye_dev (230, 1560, 8)\n",
      "pose_dev (230, 1560, 6)\n",
      "y_dev_ (230, 3)\n",
      "y_dev_ymrs (230,)\n",
      "sumerized_dev_feats (60, 154)\n",
      " pose_dev (60, 20)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# def norm(input):\n",
    "  \n",
    "#   mean = input.mean(axis=0)\n",
    "#   input -= mean\n",
    "#   std = input.std(axis=0)\n",
    "#   return input\n",
    "\n",
    "\n",
    "print('            train data          ')\n",
    "aur_train_time_w=normalize_input(aur_train_tw)\n",
    "auc_train_time_w=normalize_input(auc_train_tw)\n",
    "eye_train_time_w=normalize_input(eye_train_tw)\n",
    "pose_train_time_w=normalize_input(pose_train_tw)\n",
    "sumerized_train_feats=normalize_2d_input(sumerized_train_feats)\n",
    "\n",
    "X_train = [aur_train_time_w, auc_train_time_w, eye_train_time_w, pose_train_time_w]\n",
    "Y_train = [Y_oh_tr, Ymrs_train]\n",
    "\n",
    "\n",
    "print('aur_train',aur_train_tw.shape)\n",
    "print('auc_train',auc_train_tw.shape)\n",
    "print('eye_train',eye_train_tw.shape)\n",
    "print('pose_train',pose_train_tw.shape)\n",
    "print('y_train',Y_train[0].shape)\n",
    "print('y_train_ymrs',Y_train[1].shape)\n",
    "print('sumerized_train_feats',sumerized_train_feats.shape)\n",
    "\n",
    "\n",
    "print('                         ')\n",
    "print('*************dev data************')\n",
    "print('                         ')    \n",
    "\n",
    "aur_dev_time_w=normalize_input(aur_dev_tw)\n",
    "auc_dev_time_w=normalize_input(auc_dev_tw)\n",
    "eye_dev_time_w=normalize_input(eye_dev_tw)\n",
    "pose_dev_time_w=normalize_input(pose_dev_tw)    \n",
    "sumerized_dev_feats=normalize_2d_input(sumerized_dev_feats)\n",
    "      \n",
    "      \n",
    "X_test = [aur_dev_time_w, auc_dev_time_w, eye_dev_time_w,pose_dev_time_w]\n",
    "Y_test = [Y_oh_dev, Ymrs_dev]\n",
    "\n",
    "\n",
    "print('aur_dev',aur_dev_tw.shape)\n",
    "print('auc_dev',auc_dev_tw.shape)\n",
    "print('eye_dev',eye_dev_tw.shape)\n",
    "print('pose_dev',pose_dev_tw.shape)\n",
    "print('y_dev_',Y_test[0].shape)\n",
    "print('y_dev_ymrs',Y_test[1].shape)\n",
    "print('sumerized_dev_feats',sumerized_dev_feats.shape)\n",
    "print(' pose_dev', pose_dev.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dRRxJCtNHb79"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3284
    },
    "colab_type": "code",
    "id": "dVKsZjHzKRkm",
    "outputId": "695a719d-798e-4cf4-fb46-4523b5085040"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aur_in shape Tensor(\"AUR_input:0\", shape=(?, 1560, 17), dtype=float32)\n",
      "auc in  (?, 1560, 18)\n",
      "combined (?, 1560, 49)\n",
      "Feat combined shape (?, 1165)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "AUR_input (InputLayer)          (None, 1560, 17)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "AUC_input (InputLayer)          (None, 1560, 18)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "EYE_input (InputLayer)          (None, 1560, 8)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Pose_input (InputLayer)         (None, 1560, 6)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chan_concat (Concatenate)       (None, 1560, 49)     0           AUR_input[0][0]                  \n",
      "                                                                 AUC_input[0][0]                  \n",
      "                                                                 EYE_input[0][0]                  \n",
      "                                                                 Pose_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1560, 49)     196         chan_concat[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "seq1 (Conv1D)                   (None, 1560, 64)     15744       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1560, 64)     256         seq1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 1560, 64)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 780, 64)      0           re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "seq2 (Conv1D)                   (None, 780, 96)      30816       max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 780, 96)      384         seq2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 780, 96)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 390, 96)      0           re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "seq3 (Conv1D)                   (None, 390, 96)      46176       max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 390, 96)      384         seq3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 390, 96)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 195, 96)      0           re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "seq4 (Conv1D)                   (None, 195, 96)      46176       max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 195, 96)      384         seq4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 195, 96)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 97, 96)       0           re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "seq5 (Conv1D)                   (None, 97, 96)       46176       max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 97, 96)       384         seq5[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 97, 96)       0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 32, 96)       0           re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "seq6 (Conv1D)                   (None, 32, 96)       46176       max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 96)       384         seq6[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 32, 96)       0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 17)           0           AUR_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 17)           0           AUR_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 17)           0           AUR_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 18)           0           AUC_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 18)           0           AUC_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 18)           0           AUC_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 8)            0           EYE_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 8)            0           EYE_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 8)            0           EYE_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 6)            0           Pose_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 6)            0           Pose_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 6)            0           Pose_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 96)           0           re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 96)           0           re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 96)           0           re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 96)           0           re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 96)           0           re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 96)           0           re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 96)           0           re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 96)           0           re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 96)           0           re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "raw_globalpool_aur (Concatenate (None, 51)           0           lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "raw_globalpool_auc (Concatenate (None, 54)           0           lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "raw_globalpool_eye (Concatenate (None, 24)           0           lambda_7[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "raw_globalpool_pose (Concatenat (None, 18)           0           lambda_10[0][0]                  \n",
      "                                                                 lambda_11[0][0]                  \n",
      "                                                                 lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "OFsum_input (InputLayer)        (None, 154)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "seq_globalpool_ms (Concatenate) (None, 288)          0           lambda_13[0][0]                  \n",
      "                                                                 lambda_14[0][0]                  \n",
      "                                                                 lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "seq_globalpool_s (Concatenate)  (None, 288)          0           lambda_16[0][0]                  \n",
      "                                                                 lambda_17[0][0]                  \n",
      "                                                                 lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "seq_globalpool_8s (Concatenate) (None, 288)          0           lambda_19[0][0]                  \n",
      "                                                                 lambda_20[0][0]                  \n",
      "                                                                 lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "feat_concat (Concatenate)       (None, 1165)         0           raw_globalpool_aur[0][0]         \n",
      "                                                                 raw_globalpool_auc[0][0]         \n",
      "                                                                 raw_globalpool_eye[0][0]         \n",
      "                                                                 raw_globalpool_pose[0][0]        \n",
      "                                                                 OFsum_input[0][0]                \n",
      "                                                                 seq_globalpool_ms[0][0]          \n",
      "                                                                 seq_globalpool_s[0][0]           \n",
      "                                                                 seq_globalpool_8s[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1165)         4660        feat_concat[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1165)         0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          596992      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          262656      dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_class (Dense)               (None, 3)            1539        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_reg (Dense)                 (None, 1)            513         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,099,996\n",
      "Trainable params: 1,096,480\n",
      "Non-trainable params: 3,516\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-5039ead30920>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m#validation_split = 0.10,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreduceLR\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                    )\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 5 array(s), but instead got the following list of 4 arrays: [array([[[ 0.43786421, -0.06262726, -0.50578613, ..., -0.81615023,\n         -0.85547235,  0.48953043],\n        [ 0.18242627, -0.221799  , -0.60169014, ..., -0.79420502,\n         -0.85614046,  0.270901..."
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "clear_session()\n",
    "fitparams = dict(\n",
    "            shuffle = True,\n",
    "            batch_size =10,\n",
    "            epochs=100,\n",
    "            verbose=1)\n",
    "\n",
    "model = conv_seq()\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# keras.utils.plot_model(model, to_file='conv_seq_plot_model.png', show_shapes=True)\n",
    "# IPython.display.Image('conv_seq_plot_model.png')\n",
    "\n",
    "\n",
    "\n",
    "reduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.42, patience=12, verbose=1, mode='auto', epsilon=0.0001, cooldown=15, min_lr=1e-5)\n",
    "\n",
    "# Callbacks\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # reduceLR = ReduceLROnPlateau(monitor='loss', factor=0.42, patience=9, verbose=1, mode='auto', cooldown=10)\n",
    "# # chkpt_r = ModelCheckpoint(pth_r, monitor='val_reg_mean_absolute_error', mode='min', verbose=2, save_best_only=True, save_weights_only=True, period=1)\n",
    "# # chkpt_c = ModelCheckpoint(pth_c, monitor='val_clf_acc', mode='max', verbose=2, save_best_only=True, save_weights_only=True, period=1)\n",
    "# # chkpt_r2c = ModelCheckpoint(pth_r2c, monitor='val_reg2clf_acc', mode='max', verbose=2, save_best_only=True, save_weights_only=True, period=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Fit\n",
    "history = model.fit(**fitparams,\n",
    "            x = X_train,\n",
    "            y = Y_train,\n",
    "            validation_data = (X_test, Y_test),\n",
    "            #validation_split = 0.10,\n",
    "            callbacks=[reduceLR]\n",
    "                   )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UR8FvUeQPOKG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "1d_conv_time_series",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
